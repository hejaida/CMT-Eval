{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import random\n",
    "import copy\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import re\n",
    "import tracemalloc\n",
    "import nest_asyncio\n",
    "import dashscope\n",
    "from openai import OpenAI\n",
    "tracemalloc.start()\n",
    "nest_asyncio.apply()\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_samples_from_json(filename, start, end=None, num_samples=None):\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as jsonfile:\n",
    "            data = json.load(jsonfile)\n",
    "\n",
    "            if end is not None:\n",
    "                samples = data[start:end]\n",
    "            elif num_samples is not None:\n",
    "                samples = data[start:start + num_samples]\n",
    "            else:\n",
    "                samples = data[start:]\n",
    "\n",
    "            print('读取源数据成功。')\n",
    "            return samples\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error reading JSON file: {e}\")\n",
    "        return []\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {e}\")\n",
    "        return []\n",
    "\n",
    "def load_prompt_from_txt(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            prompt = file.read().strip() \n",
    "            if not prompt:  \n",
    "                print(\"Prompt file is empty. Proceeding with an empty prompt.\")\n",
    "                return \"\"  \n",
    "            return prompt\n",
    "    except FileNotFoundError:\n",
    "        raise ValueError(f\"Prompt file not found: {file_path}\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading prompt: {e}\")\n",
    "\n",
    "async def fetch_content_multi_round(session, conversation_history, api_key, temperature, max_tokens, url, retries=10):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            async with session.post(\n",
    "                url=f\"{url}/chat/completions\",\n",
    "                json={\n",
    "                    \"model\": \"\",\n",
    "                    \"messages\": conversation_history,\n",
    "                    \"temperature\": temperature,\n",
    "                    \"max_tokens\": max_tokens,\n",
    "                },\n",
    "                headers={\"Authorization\": f\"Bearer {api_key}\"}\n",
    "            ) as response:\n",
    "                if response.status != 200:\n",
    "                    raise ValueError(f\"API Error: {response.status} - {await response.text()}\")\n",
    "\n",
    "                completion = await response.json()\n",
    "\n",
    "                print(f\"Raw completion response: {completion}\")\n",
    "\n",
    "                if \"choices\" in completion and len(completion[\"choices\"]) > 0:\n",
    "                    generated_content = completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "                    print(\"Generated content:\", generated_content)\n",
    "                    return (\n",
    "                        generated_content,\n",
    "                        completion.get(\"usage\", {}).get(\"completion_tokens\", 0),\n",
    "                        completion.get(\"usage\", {}).get(\"total_tokens\", 0),\n",
    "                    )\n",
    "                else:\n",
    "                    print(\"Error: No valid content in response.\")\n",
    "                    return None, 0, 0\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1}/{retries}: Error during request: {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                print(\"Retrying...\")\n",
    "            else:\n",
    "                print(\"Exhausted retries.\")\n",
    "    return None, 0, 0\n",
    "\n",
    "async def generate_content_multi_round(samples, prompt, api_key,temperature, max_tokens, url,output_file_path, batch_size=3, sleep_interval=2):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for i in range(0, len(samples), batch_size):\n",
    "            batch_samples = samples[i:i + batch_size]\n",
    "\n",
    "            for sample in batch_samples:\n",
    "                conversation_history = []\n",
    "\n",
    "                original_data = {\n",
    "                    \"origin_id\": sample.get(\"origin_id\"),\n",
    "                    \"评测能力\": sample.get(\"评测能力\"),\n",
    "                    \"用户角色\": sample.get(\"用户角色\")\n",
    "                }\n",
    "\n",
    "                if prompt:\n",
    "                    conversation_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "                for round_data in sample[\"会话内容\"]:\n",
    "                    query = round_data.get(\"用户query\", \"\")\n",
    "                    if query:\n",
    "                        conversation_history.append({\"role\": \"user\", \"content\": query})\n",
    "\n",
    "                        round_data_copy = copy.deepcopy(round_data)\n",
    "                        round_data_copy.pop(\"预设回复\", None)\n",
    "                        round_data_copy.pop(\"难度设计方法\", None)\n",
    "\n",
    "                        generated_content, _, _ = await fetch_content_multi_round(\n",
    "                            session,\n",
    "                            copy.deepcopy(conversation_history),\n",
    "                            api_key,\n",
    "                            temperature,\n",
    "                            max_tokens,\n",
    "                            url=url\n",
    "                        )\n",
    "\n",
    "                        if generated_content:\n",
    "                            conversation_history.append({\"role\": \"assistant\", \"content\": generated_content})\n",
    "                            round_data[\"模型回复\"] = generated_content\n",
    "\n",
    "                print(f\"Writing complete conversation for ID {sample['origin_id']} to file.\")\n",
    "                sample.update(original_data)\n",
    "\n",
    "                try:\n",
    "                    await write_to_json_file([sample], output_file_path)\n",
    "                    print(f\"Successfully written complete conversation for ID {sample['origin_id']} to {output_file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error writing complete conversation for ID {sample['origin_id']} to file: {e}\")\n",
    "\n",
    "            if i + batch_size < len(samples):\n",
    "                print(f\"Sleeping for {sleep_interval} seconds before processing next batch...\")\n",
    "                await asyncio.sleep(sleep_interval)\n",
    "                \n",
    "async def write_to_json_file(data, filename):\n",
    "    try:\n",
    "        with open(filename, 'r+', encoding='utf-8') as jsonfile:\n",
    "            try:\n",
    "                existing_data = json.load(jsonfile)\n",
    "            except json.JSONDecodeError:\n",
    "                existing_data = []  \n",
    "            existing_data.append(data)  \n",
    "            jsonfile.seek(0)\n",
    "            json.dump(existing_data, jsonfile, ensure_ascii=False, indent=2)\n",
    "    except FileNotFoundError:\n",
    "        with open(filename, 'w', encoding='utf-8') as jsonfile:\n",
    "            json.dump([data], jsonfile, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main(input_file_path, prompt_file_path, output_file_path, start, end=None, num_samples=None, api_key=None,temperature=0, max_tokens=8000,url=None):\n",
    "    if not url or not isinstance(url, str):\n",
    "        raise ValueError(\"Invalid URL. Please provide a valid URL string.\")\n",
    "    print(f\"Initial URL type: {type(url)}, value: {url}\")\n",
    "\n",
    "    output_dir = os.path.dirname(output_file_path)\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)  \n",
    "\n",
    "    samples = load_samples_from_json(input_file_path, start=start, end=end, num_samples=num_samples)\n",
    "    if not samples:\n",
    "        raise ValueError(\"No samples loaded. Please check the input file and specified range.\")\n",
    "    print(f\"Loaded {len(samples)} samples for processing.\")\n",
    "\n",
    "    prompt = load_prompt_from_txt(prompt_file_path)\n",
    "    if not prompt:\n",
    "        print(\"Notice: Prompt is empty. Proceeding without a system prompt.\")\n",
    "\n",
    "    try:\n",
    "        await generate_content_multi_round(samples, prompt, api_key, temperature, max_tokens, url,output_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during content generation: {e}\")\n",
    "        return\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    start = \n",
    "    num_samples = \n",
    "    temperature = 0.2\n",
    "    max_tokens = 8000\n",
    "\n",
    "    input_file_path = ''\n",
    "    prompt_file_path = ''\n",
    "    output_file_path = ''\n",
    "    \n",
    "    api_key = ''\n",
    "    url = ''\n",
    "\n",
    "try:\n",
    "    asyncio.run(main(\n",
    "        input_file_path=input_file_path,\n",
    "        prompt_file_path=prompt_file_path,\n",
    "        output_file_path=output_file_path,\n",
    "        start=start,\n",
    "        num_samples=num_samples,\n",
    "        api_key=api_key,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        url=url\n",
    "    ))\n",
    "except Exception as e:\n",
    "    print(f\"Error running main function: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
