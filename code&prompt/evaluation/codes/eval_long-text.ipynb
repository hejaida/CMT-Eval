{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import random\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import re\n",
    "import tracemalloc\n",
    "import nest_asyncio\n",
    "import logging \n",
    "import os\n",
    "from openai import OpenAI\n",
    "tracemalloc.start()\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s [%(funcName)s:%(lineno)d]')\n",
    "\n",
    "def load_prompt_from_txt(filename):\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as txtfile:\n",
    "            prompt = txtfile.read().strip()\n",
    "            #logging.info(f\"成功读取Prompt文件: {filename}\")\n",
    "            return prompt\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Prompt文件未找到: {filename}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"读取Prompt文件时发生错误: {e}\")\n",
    "    return \"\"\n",
    "\n",
    "def load_samples_from_json(file1, file2, start, num_samples=None):\n",
    "    try:\n",
    "        # 读取并解析文件1\n",
    "        with open(file1, 'r', encoding='utf-8') as f1:\n",
    "            data1 = json.load(f1)\n",
    "            logging.info(f\"文件1加载成功，共有 {len(data1)} 条样本\")\n",
    "\n",
    "        # 读取并解析文件2\n",
    "        with open(file2, 'r', encoding='utf-8-sig') as f2:\n",
    "            data2 = json.load(f2)\n",
    "\n",
    "        logging.info(f\"文件2加载成功，原始样本数: {len(data2)}\")\n",
    "\n",
    "        def flatten_nested_list(data):\n",
    "            result = []\n",
    "            for item in data:\n",
    "                if isinstance(item, list):\n",
    "                    result.extend(flatten_nested_list(item))\n",
    "                else:\n",
    "                    result.append(item)\n",
    "            return result\n",
    "\n",
    "        data2 = flatten_nested_list(data2)\n",
    "\n",
    "        logging.info(f\"文件2展平后样本数: {len(data2)}\")\n",
    "\n",
    "        # 2. 基于start和num_samples找到文件2中的样本\n",
    "        start = max(0, start)\n",
    "        end = min(start + (num_samples or len(data2)), len(data2))\n",
    "\n",
    "        if start >= len(data2):\n",
    "            logging.error(f\"起始索引超出样本长度，样本总数: {len(data2)}\")\n",
    "            return []\n",
    "\n",
    "        selected_data2 = data2[start:end]\n",
    "        logging.info(f\"选取的文件2样本数量: {len(selected_data2)}\")\n",
    "\n",
    "        # 3. 读取文件2中的样本ID\n",
    "        selected_ids = {str(item.get('ID')) for item in selected_data2 if 'ID' in item}\n",
    "        logging.info(f\"选取的样本ID: {selected_ids}\")\n",
    "\n",
    "        # 4. 基于文件1和文件2，匹配文件1中的相关字段\n",
    "        matched_samples = []\n",
    "\n",
    "        for item1 in data1:\n",
    "            item_id = str(item1.get('ID'))\n",
    "            if item_id in selected_ids:\n",
    "                qa_pairs_str = item1.get(\"qa_pairs\", \"[]\")\n",
    "                #logging.info(f\"直接保留 ID={item_id} 的 qa_pairs 字符串，不解析。\")\n",
    "\n",
    "                matched_data = {\n",
    "                    \"ID\": item_id,\n",
    "                    \"summary\": item1.get(\"summary\"),\n",
    "                    \"qa_pairs\": qa_pairs_str,  # 直接作为字符串\n",
    "                    \"会话内容\": next((item for item in selected_data2 if str(item.get('ID')) == item_id), {}).get(\"会话内容\", [])\n",
    "                }\n",
    "                matched_samples.append(matched_data)\n",
    "\n",
    "        logging.info(f\"最终匹配的样本数量: {len(matched_samples)}\")\n",
    "\n",
    "        return matched_samples\n",
    "\n",
    "    except (FileNotFoundError, json.JSONDecodeError, KeyError, ValueError) as e:\n",
    "        logging.error(f\"文件处理失败: {e}\")\n",
    "        return []\n",
    "    \n",
    "def process_conversation(conversation):\n",
    "    for round_data in conversation:\n",
    "        if round_data.get(\"轮次\") == 1:\n",
    "            user_query = round_data.get(\"用户query\", \"\")\n",
    "            if \"\\n\" in user_query:\n",
    "                round_data[\"用户query\"] = user_query.split(\"\\n\", 1)[1]\n",
    "                #logging.info(f\"更新轮次1的用户query: {round_data['用户query']}\")\n",
    "    return conversation\n",
    "\n",
    "def format_conversation_text(conversation):\n",
    "    try:\n",
    "        valid_conversation = [round_data for round_data in conversation if isinstance(round_data, dict)]\n",
    "        conversation_text = \"\\n\".join([\n",
    "            f\"轮次 {round_data.get('轮次', '未知')} - 用户: {round_data.get('用户query', '未知')}\\n\"\n",
    "            f\"模型: {round_data.get('模型回复', '未知')}\\n言语行为: {round_data.get('言语行为', '未知')}\"\n",
    "            for round_data in valid_conversation\n",
    "        ])\n",
    "        #logging.info(f\"生成的对话文本:\\n{conversation_text}\")\n",
    "        return conversation_text\n",
    "    except Exception as e:\n",
    "        logging.error(f\"生成对话文本时发生错误: {e}\")\n",
    "        return None\n",
    "\n",
    "async def fetch_content(samples, prompt, api_key, url, output_file_path):\n",
    "    batch_size = \n",
    "    retries = 10\n",
    "    delay = 2\n",
    "\n",
    "    for batch_index in range(0, len(samples), batch_size):\n",
    "        batch = samples[batch_index:batch_index + batch_size]\n",
    "\n",
    "        logging.info(f\"开始处理第 {batch_index // batch_size + 1} 批次，共 {len(batch)} 条样本\")\n",
    "\n",
    "        for sample_index, sample in enumerate(batch):\n",
    "            sample_id = sample.get('ID', '未知')\n",
    "            logging.info(f\"正在处理第 {batch_index // batch_size + 1} 批次的第 {sample_index + 1} 个会话，ID: {sample_id}\")\n",
    "\n",
    "            attempt = 0\n",
    "            while attempt < retries:\n",
    "                try:\n",
    "                    summary = sample.get(\"summary\", \"\")\n",
    "                    qa_pairs_str = sample.get(\"qa_pairs\", \"[]\")\n",
    "                    conversation = sample.get(\"会话内容\", [])\n",
    "\n",
    "                    conversation_text = format_conversation_text(conversation)\n",
    "                    if not conversation_text:\n",
    "                        logging.error(f\"样本 ID: {sample_id} 会话内容格式化失败，跳过。\")\n",
    "                        break\n",
    "\n",
    "                    input_content = {\n",
    "                        \"summary\": f\"<summary>{summary}</summary>\",\n",
    "                        \"qa_pairs\": f\"<qa_pairs>{qa_pairs_str}</qa_pairs>\",\n",
    "                        \"conversation\": f\"<会话>{conversation_text}</会话>\"\n",
    "                    }\n",
    "\n",
    "                    client = OpenAI(base_url=url, api_key=api_key)\n",
    "                    completion = client.chat.completions.create(\n",
    "                        model=\"anthropic/claude-3.5-sonnet\",\n",
    "                        messages=[\n",
    "                            {\n",
    "                                \"role\": \"user\",\n",
    "                                \"content\": f\"{prompt} {json.dumps(input_content, ensure_ascii=False, indent=2)}\"\n",
    "                            }\n",
    "                        ],\n",
    "                        temperature=0.1,\n",
    "                        max_tokens=20000\n",
    "                    )\n",
    "\n",
    "                    if completion.choices and len(completion.choices) > 0:\n",
    "                        raw_result = completion.choices[0].message.content\n",
    "                        logging.info(raw_result)\n",
    "                        logging.info(f\"样本 ID: {sample_id} 处理成功，立即写入文件\")\n",
    "\n",
    "                        add_generated_content_to_data([sample], [raw_result], output_file_path)\n",
    "                        break \n",
    "                    else:\n",
    "                        logging.warning(f\"样本 ID: {sample_id} 响应中无有效内容。\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"样本 ID: {sample_id} 请求失败，重试 {attempt + 1}/{retries} 次... 错误: {e}\")\n",
    "                    attempt += 1\n",
    "                    await asyncio.sleep(delay)\n",
    "\n",
    "                if attempt == retries:\n",
    "                    logging.error(f\"样本 ID: {sample_id} 多次请求失败，跳过。\")\n",
    "\n",
    "        logging.info(f\"批次 {batch_index // batch_size + 1} 处理完成，共 {len(batch)} 条样本\")\n",
    "\n",
    "def extract_evaluations(model_output):\n",
    "    def preprocess_text(text):\n",
    "        text = text.strip()\n",
    "        text = text.replace(\"：\", \":\")  \n",
    "        text = text.replace(\"\\r\\n\", \"\\n\")  \n",
    "        text = re.sub(r\"\\s+\", \" \", text) \n",
    "        text = re.sub(r\"(?<!\\n)轮次\\s*:\\s*(\\d+)\", r\"\\n轮次:\\1\", text)\n",
    "        return text\n",
    "\n",
    "    def expand_rounds(round_str):\n",
    "        rounds = []\n",
    "        if \"-\" in round_str:\n",
    "            start, end = map(int, round_str.split(\"-\"))\n",
    "            rounds = list(range(start, end + 1))\n",
    "        else:\n",
    "            rounds.append(int(round_str))\n",
    "        return rounds\n",
    "\n",
    "    processed_text = preprocess_text(model_output)\n",
    "\n",
    "    round_pattern = re.compile(\n",
    "    r'\"轮次\":\\s*\"(\\d+(?:-\\d+)?)\"'\n",
    "    r'\"统筹能力\":\\s*(?:\")?(\\d+)(?:\")?'\n",
    "    r'\"适应能力\":\\s*(?:\")?(\\d+)(?:\")?'\n",
    "    r'\"评分理由\":\\s*\"([^\"]+)\"',\n",
    "    re.S\n",
    ")\n",
    "\n",
    "    matches = round_pattern.findall(processed_text)\n",
    "\n",
    "    if not matches:\n",
    "        logging.warning(\"未找到任何评分内容，请检查文本格式。\")\n",
    "        return {\"round_evaluations\": {}}\n",
    "\n",
    "    round_evaluations = {}\n",
    "    for match in matches:\n",
    "        round_range = match[0]  \n",
    "        overall_skill = int(match[1])  \n",
    "        adaptation_skill = int(match[2])  \n",
    "        reason = match[3].strip().replace(\"\\n\", \" \")  \n",
    "\n",
    "        expanded_rounds = expand_rounds(round_range)\n",
    "\n",
    "        for round_number in expanded_rounds:\n",
    "            round_evaluations[f\"轮次{round_number}\"] = {\n",
    "                \"统筹能力\": overall_skill,\n",
    "                \"适应能力\": adaptation_skill,\n",
    "                \"评分理由\": reason\n",
    "            }\n",
    "\n",
    "    return {\"round_evaluations\": round_evaluations}\n",
    "\n",
    "def add_generated_content_to_data(samples, generated_contents, output_file_path):\n",
    "    DEFAULT_EVALUATION = {\n",
    "        \"统筹能力\": 3,\n",
    "        \"适应能力\": 3,\n",
    "        \"评分理由\": \"默认理由\"\n",
    "    }\n",
    "\n",
    "    for sample, evaluation_text in zip(samples, generated_contents):\n",
    "        sample_id = sample.get('ID', '未知')\n",
    "\n",
    "        logging.info(f\"正在处理会话 ID: {sample_id} 并写入文件\")\n",
    "\n",
    "        if evaluation_text:\n",
    "            try:\n",
    "                evaluation_data = extract_evaluations(evaluation_text)\n",
    "                round_evaluations = evaluation_data.get(\"round_evaluations\", {})\n",
    "\n",
    "                if not round_evaluations:\n",
    "                    logging.warning(f\"样本 ID: {sample_id} 提取评分失败，使用默认评分\")\n",
    "\n",
    "                round_scores = []\n",
    "                for round_index, round_data in enumerate(sample.get(\"会话内容\", []), start=1):\n",
    "                    eval_data = round_evaluations.get(f\"轮次{round_index}\", {})\n",
    "\n",
    "                    for key in [\"统筹能力\", \"适应能力\", \"评分理由\"]:\n",
    "                        eval_data.setdefault(key, DEFAULT_EVALUATION[key])\n",
    "\n",
    "                    eval_data[\"本轮评分\"] = round((eval_data[\"统筹能力\"] + eval_data[\"适应能力\"]) / 2, 2)\n",
    "                    round_scores.append(eval_data[\"本轮评分\"])\n",
    "\n",
    "                    round_data.update(eval_data)\n",
    "\n",
    "                sample[\"整体评分\"] = round(sum(round_scores) / len(round_scores), 2) if round_scores else 3.00\n",
    "\n",
    "                write_to_json_file(sample, output_file_path)\n",
    "                logging.info(f\"样本 ID: {sample_id} 已成功写入到 {output_file_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"处理样本 ID: {sample_id} 时出错: {e}\")\n",
    "        else:\n",
    "            logging.warning(f\"样本 ID: {sample_id} 生成内容为空，跳过。\")\n",
    "            \n",
    "def write_to_json_file(data, filename):\n",
    "    try:\n",
    "        with open(filename, 'r+', encoding='utf-8') as jsonfile:\n",
    "            try:\n",
    "                existing_data = json.load(jsonfile)\n",
    "            except json.JSONDecodeError:\n",
    "                existing_data = [] \n",
    "            \n",
    "            existing_data.append(data) \n",
    "            jsonfile.seek(0)\n",
    "            json.dump(existing_data, jsonfile, ensure_ascii=False, indent=2)\n",
    "\n",
    "        logging.info(f\"数据已成功写入文件: {filename}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        with open(filename, 'w', encoding='utf-8') as jsonfile:\n",
    "            json.dump([data], jsonfile, ensure_ascii=False, indent=2)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"写入文件时出错: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main(file1_path, file2_path, prompt_file_path, output_file_path, start, num_samples, api_key, url):\n",
    "    try:\n",
    "        logging.info(\"开始主流程...\")\n",
    "\n",
    "        samples = load_samples_from_json(file1_path, file2_path, start, num_samples)\n",
    "        if not samples:\n",
    "            logging.error(\"样本数据加载失败，流程终止。\")\n",
    "            return\n",
    "        logging.info(f\"成功加载 {len(samples)} 条样本数据。\")\n",
    "\n",
    "        prompt = load_prompt_from_txt(prompt_file_path)\n",
    "        if not prompt:\n",
    "            logging.error(\"Prompt 加载失败，流程终止。\")\n",
    "            return\n",
    "        logging.info(f\"成功加载 Prompt，长度: {len(prompt)} 个字符\")\n",
    "\n",
    "        for sample in samples:\n",
    "            sample[\"会话内容\"] = process_conversation(sample.get(\"会话内容\", []))\n",
    "\n",
    "        logging.info(\"样本数据预处理完成，开始调用模型...\")\n",
    "\n",
    "        try:\n",
    "            await asyncio.wait_for(fetch_content(samples, prompt, api_key, url, output_file_path), timeout=600)\n",
    "            logging.info(\"模型调用完成。\")\n",
    "        except asyncio.TimeoutError:\n",
    "            logging.error(\"模型调用超时，流程终止。\")\n",
    "            return\n",
    "\n",
    "        if os.path.exists(output_file_path) and os.path.getsize(output_file_path) > 0:\n",
    "            logging.info(f\"生成结果已成功保存到 {output_file_path}\")\n",
    "        else:\n",
    "            logging.error(\"所有会话请求均失败，未写入任何数据。\")\n",
    "            return\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        logging.error(f\"文件未找到: {e}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f\"JSON解析错误: {e}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"主流程执行时发生异常: {e}\", exc_info=True)\n",
    "        \n",
    "# 运行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    file1_path = '' #summary & QA\n",
    "    file2_path = ''\n",
    "    prompt_file_path = ''\n",
    "    output_file_path = ''\n",
    "    \n",
    "    start = \n",
    "    num_samples = \n",
    "\n",
    "    api_key = ''\n",
    "    url = ''\n",
    "    asyncio.run(main(file1_path, file2_path, prompt_file_path, output_file_path, start, num_samples, api_key, url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
