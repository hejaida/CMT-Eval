{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import random\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import re\n",
    "import tracemalloc\n",
    "import nest_asyncio\n",
    "import logging \n",
    "from openai import OpenAI\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "tracemalloc.start()\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s [%(funcName)s:%(lineno)d]')\n",
    "\n",
    "def load_samples_from_json(filename, start_list, num_samples=None, batch_size=3, sleep_time_range=(1, 2), prompt=None, client=None, output_file_path=None):\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as jsonfile:\n",
    "            data = json.load(jsonfile)\n",
    "\n",
    "            if not isinstance(data, list):\n",
    "                logging.error(f\"文件内容格式错误，应为列表: {filename}\")\n",
    "                return []\n",
    "\n",
    "            flattened_data = [sample[0] for sample in data if isinstance(sample, list) and len(sample) > 0]\n",
    "\n",
    "            for start in start_list:\n",
    "                if start < 0 or (num_samples is not None and num_samples < 0):\n",
    "                    logging.error(f\"无效的参数: start={start}, num_samples={num_samples}\")\n",
    "                    continue\n",
    "\n",
    "                if start >= len(flattened_data):\n",
    "                    logging.error(f\"起始行超出数据长度: 数据长度={len(flattened_data)}, start={start}\")\n",
    "                    continue\n",
    "\n",
    "                end = start + num_samples if num_samples is not None else len(flattened_data)\n",
    "                samples = flattened_data[start:end]\n",
    "                logging.info(f\"成功读取源数据: {len(samples)} 条记录 (范围: {start}-{end - 1 if num_samples else '末尾'}).\")\n",
    "\n",
    "                for i in range(0, len(samples), batch_size):\n",
    "                    batch_samples = samples[i:i + batch_size]\n",
    "                    logging.info(f\"开始处理第 {i + 1}-{i + len(batch_samples)} 条样本\")\n",
    "\n",
    "                    for sample in batch_samples:\n",
    "                        conversation = sample.get('会话内容', [])\n",
    "                        if isinstance(conversation, list):\n",
    "                            result = fetch_content(client, conversation, prompt)\n",
    "                            if result:\n",
    "                                add_generated_content_to_data([sample], [result], output_file_path)\n",
    "                                logging.info(f\"样本 {sample.get('origin_id', '未知')} 已成功写入\")\n",
    "                            else:\n",
    "                                logging.warning(f\"样本 {sample.get('origin_id', '未知')} 未能生成内容\")\n",
    "                        else:\n",
    "                            logging.warning(f\"样本 {sample.get('origin_id', '未知')} 的 '会话内容' 格式错误，跳过处理\")\n",
    "\n",
    "                    sleep_time = random.uniform(*sleep_time_range)\n",
    "                    logging.info(f\"批次处理完毕，暂停 {sleep_time:.2f} 秒\")\n",
    "                    time.sleep(sleep_time)\n",
    "\n",
    "        return True\n",
    "    except (json.JSONDecodeError, FileNotFoundError) as e:\n",
    "        logging.error(f\"文件读取失败: {filename}, 错误: {e}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"意外错误: {e}\")\n",
    "    return False\n",
    "\n",
    "def load_prompt_from_txt(filename):\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as txtfile:\n",
    "            prompt = txtfile.read().strip()\n",
    "            logging.info(f\"成功读取Prompt文件: {filename}\")\n",
    "            return prompt\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Prompt文件未找到: {filename}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"读取Prompt文件时发生错误: {e}\")\n",
    "    return \"\"\n",
    "\n",
    "def fetch_content(client, conversation, prompt, max_retries=10, initial_wait=1):\n",
    "    if not isinstance(conversation, list):\n",
    "        logging.error(f\"conversation 应该是一个字典列表，但收到类型: {type(conversation)}\")\n",
    "        return None\n",
    "\n",
    "    valid_conversation = [round_data for round_data in conversation if isinstance(round_data, dict)]\n",
    "    if not valid_conversation:\n",
    "        logging.error(\"conversation 中没有有效的字典元素，无法生成对话文本。\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        conversation_text = \"\\n\".join([\n",
    "            f\"轮次 {round_data.get('轮次', '未知')} - 用户: {round_data.get('用户query', '未知')}\\n\"\n",
    "            f\"模型: {round_data.get('模型回复', '未知')}\\n言语行为: {round_data.get('言语行为', '未知')}\"\n",
    "            for round_data in valid_conversation\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        logging.error(f\"生成对话文本时发生错误: {e}\")\n",
    "        return None\n",
    "\n",
    "    input_content = {\n",
    "        \"conversation\": conversation_text\n",
    "    }\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            logging.info(f\"尝试调用模型: 第 {attempt + 1}/{max_retries} 次\")\n",
    "\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"anthropic/claude-3.5-sonnet\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"{prompt} <会话>{json.dumps(input_content, ensure_ascii=False, indent=2)}</会话>\"\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0,\n",
    "                top_p=0.1,\n",
    "                max_tokens=20000,\n",
    "                seed=12,\n",
    "                stream=True\n",
    "            )\n",
    "\n",
    "            if completion.choices and len(completion.choices) > 0:\n",
    "                generated_content = completion.choices[0].message.content\n",
    "                logging.info(f\"完整响应: {completion}\")\n",
    "\n",
    "                if generated_content:\n",
    "                    logging.info(f\"模型生成的内容:\\n{generated_content}\")\n",
    "                    return generated_content\n",
    "                else:\n",
    "                    logging.error(\"模型生成的内容为空\")\n",
    "            else:\n",
    "                logging.error(\"模型返回的 choices 字段为空或缺失\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"调用模型时发生错误: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = initial_wait * (2 ** attempt)  \n",
    "                logging.info(f\"将在 {wait_time} 秒后重试...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                logging.error(\"已达到最大重试次数，无法完成请求。\")\n",
    "                return None\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_evaluations(model_output):\n",
    "    def preprocess_text(text):\n",
    "        \"\"\"\n",
    "        预处理文本，统一格式，确保数据一致性。\n",
    "        \"\"\"\n",
    "        text = text.strip()\n",
    "        text = text.replace(\"：\", \":\") \n",
    "        text = text.replace(\"\\r\\n\", \"\\n\") \n",
    "        text = re.sub(r\"\\s+\", \" \", text) \n",
    "        text = re.sub(r\"(?<!\\n)轮次\\s*:\\s*(\\d+)\", r\"\\n轮次:\\1\", text)\n",
    "        return text\n",
    "\n",
    "    def expand_rounds(round_str):\n",
    "        \"\"\"\n",
    "        解析轮次信息，处理单个数字和范围（如6-8），返回轮次列表。\n",
    "        \"\"\"\n",
    "        rounds = []\n",
    "        if \"-\" in round_str:\n",
    "            start, end = map(int, round_str.split(\"-\"))\n",
    "            rounds = list(range(start, end + 1))\n",
    "        else:\n",
    "            rounds.append(int(round_str))\n",
    "        return rounds\n",
    "\n",
    "    processed_text = preprocess_text(model_output)\n",
    "\n",
    "    round_pattern = re.compile(\n",
    "    r'\"轮次\":\\s*\"(\\d+(?:-\\d+)?)\"'\n",
    "    r'\"统筹能力\":\\s*(?:\")?(\\d+)(?:\")?'\n",
    "    r'\"适应能力\":\\s*(?:\")?(\\d+)(?:\")?'\n",
    "    r'\"评分理由\":\\s*\"([^\"]+)\"',\n",
    "    re.S\n",
    ")\n",
    "\n",
    "    matches = round_pattern.findall(processed_text)\n",
    "\n",
    "    if not matches:\n",
    "        logging.warning(\"未找到任何评分内容，请检查文本格式。\")\n",
    "        return {\"round_evaluations\": {}}\n",
    "\n",
    "    round_evaluations = {}\n",
    "    for match in matches:\n",
    "        round_range = match[0]  \n",
    "        overall_skill = int(match[1])  \n",
    "        adaptation_skill = int(match[2])  \n",
    "        reason = match[3].strip().replace(\"\\n\", \" \")  \n",
    "\n",
    "        expanded_rounds = expand_rounds(round_range)\n",
    "\n",
    "        for round_number in expanded_rounds:\n",
    "            round_evaluations[f\"轮次{round_number}\"] = {\n",
    "                \"统筹能力\": overall_skill,\n",
    "                \"适应能力\": adaptation_skill,\n",
    "                \"评分理由\": reason\n",
    "            }\n",
    "\n",
    "    return {\"round_evaluations\": round_evaluations}\n",
    "\n",
    "def add_generated_content_to_data(samples, generated_contents, output_file_path):\n",
    "    for i, sample in enumerate(samples):\n",
    "        if i < len(generated_contents):\n",
    "            evaluation_text = generated_contents[i]\n",
    "            if evaluation_text:\n",
    "                try:\n",
    "                    evaluation_data = extract_evaluations(evaluation_text)\n",
    "                    round_evaluations = evaluation_data.get(\"round_evaluations\", {})\n",
    "\n",
    "                    if not round_evaluations:\n",
    "                        logging.warning(f\"样本 {sample.get('origin_id', '未知')} 提取评分失败，将使用默认评分\")\n",
    "\n",
    "                    logging.info(f\"提取的评分数据: {round_evaluations}\")\n",
    "\n",
    "                    round_scores = []  \n",
    "\n",
    "                    for j, round_data in enumerate(sample.get(\"会话内容\", []), start=1):\n",
    "                        eval_data = round_evaluations.get(f\"轮次{j}\", {})  \n",
    "\n",
    "                        for key in [\"统筹能力\", \"适应能力\", \"评分理由\"]:\n",
    "                            if key not in eval_data:\n",
    "                                logging.warning(f\"轮次 {j} 的评分 {key} 缺失，使用默认值\")\n",
    "                                eval_data[key] = DEFAULT_EVALUATION[key]\n",
    "\n",
    "                        eval_data[\"本轮评分\"] = round((eval_data[\"统筹能力\"] + eval_data[\"适应能力\"]) / 2, 2)\n",
    "                        round_scores.append(eval_data[\"本轮评分\"])  \n",
    "\n",
    "                        round_data.update(eval_data)\n",
    "\n",
    "                    round_avg_score = round(sum(round_scores) / len(round_scores), 2) if round_scores else 3.00\n",
    "                    sample[\"整体评分\"] = round_avg_score\n",
    "\n",
    "                    logging.info(f\"样本 {sample.get('origin_id', '未知')} 更新完成，总轮次: {len(round_scores)}, 整体评分: {round_avg_score:.2f}\")\n",
    "\n",
    "                    write_to_json_file(sample, output_file_path)\n",
    "                    logging.info(f\"Successfully written complete conversation for origin_id {sample['origin_id']} to {output_file_path}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"处理样本 {sample.get('origin_id', '未知')} 时出错: {e}\")\n",
    "            else:\n",
    "                logging.warning(f\"样本 {sample.get('origin_id', '未知')} 生成内容为空，跳过。\")\n",
    "        else:\n",
    "            logging.warning(f\"未生成评估内容，样本 {sample.get('origin_id', '未知')} 跳过。\")\n",
    "\n",
    "def write_to_json_file(data, filename):\n",
    "    try:\n",
    "        with open(filename, 'r+', encoding='utf-8') as jsonfile:\n",
    "            try:\n",
    "                existing_data = json.load(jsonfile)\n",
    "            except json.JSONDecodeError:\n",
    "                existing_data = []  \n",
    "            \n",
    "            existing_data.append(data) \n",
    "            jsonfile.seek(0)\n",
    "            json.dump(existing_data, jsonfile, ensure_ascii=False, indent=2)\n",
    "\n",
    "        logging.info(f\"数据已成功写入文件: {filename}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        with open(filename, 'w', encoding='utf-8') as jsonfile:\n",
    "            json.dump([data], jsonfile, ensure_ascii=False, indent=2)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"写入文件时出错: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def main(input_file_path, output_file_path, start_list, num_samples, api_key, url):\n",
    "    try:\n",
    "        logging.info(f\"加载样本数据和 Prompt 内容...\")\n",
    "\n",
    "        if not os.path.exists(input_file_path):\n",
    "            logging.error(f\"输入文件不存在: {input_file_path}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        prompt_file_path = os.path.abspath('')\n",
    "        if not os.path.exists(prompt_file_path):\n",
    "            logging.error(f\"Prompt 文件不存在: {prompt_file_path}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        prompt_content = load_prompt_from_txt(prompt_file_path)\n",
    "        if not prompt_content:\n",
    "            logging.error(\"Prompt 内容加载失败，流程终止。\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        logging.info(\"初始化...\")\n",
    "        client = OpenAI(base_url=url, api_key=api_key)\n",
    "\n",
    "        success = load_samples_from_json(input_file_path, start_list, num_samples, prompt=prompt_content, client=client, output_file_path=output_file_path)\n",
    "\n",
    "        if success:\n",
    "            logging.info(f\"所有样本已处理完毕，结果保存在 {output_file_path}\")\n",
    "        else:\n",
    "            logging.error(\"样本处理过程中发生错误，未能完成处理。\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"主流程执行时发生异常: {e}\", exc_info=True)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    input_file_path = ''\n",
    "    prompt_file_path = ''\n",
    "    output_file_path = ''\n",
    "    start_list = []\n",
    "    num_samples =\n",
    "\n",
    "    api_key = ''\n",
    "    url = ''\n",
    "    \n",
    "    prompt = load_prompt_from_txt(prompt_file_path)\n",
    "    if not prompt:\n",
    "        logging.error(\"Prompt 内容加载失败，流程终止。\")\n",
    "        exit(1)\n",
    "\n",
    "    main(input_file_path, output_file_path, start_list, num_samples, api_key, url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
