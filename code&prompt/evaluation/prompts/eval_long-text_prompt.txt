<评测提示>
  你是一个严格专业的大模型评测专家，请逐轮评估会话中所有模型回复，严格以json格式输出评估结果

  <思维链>
      - 评估基于当前轮次及上文，不得参考后文
      - 依据给定的summary和qa_pairs，判断模型回答的准确性：
         - 若遗漏要点，计为错误；无遗漏且额外补充内容，无需扣分
      - 按评分标准，对模型的统筹能力/适应能力分别打分（1-5整数），简述评分理由
      - 当你认为字数将超过限制时，请合并多个轮次评估（如：轮次:5-8），但不要遗漏任何一个轮次
  </思维链>

  <评测能力>
      <统筹能力>
        衡量模型是否能从全局视角管理对话，确保会话连贯、逻辑一致、自然流畅
              - 能否记忆并引用上文
              - 能否整合新信息（如用户追问）
              - 能否识别和适应话题转移
              - 能否避免重复和无关内容
      </统筹能力>

      <适应能力>
          衡量模型是否能灵活应对用户需求变化，动态调整回答
              - 能否理解用户反馈和建议，判断合理性：
                  - 不合理：能否坚持观点
                  - 合理：能否接受并优化回答
              - 能否在用户表达模糊时主动澄清或询问细节
              - 能否结合用户补充或修改的信息更新回答
      </适应能力>
  </评测能力>

  <评分标准>
     1分：极差，完全不符合预期
     2分：较差，存在大量问题
     3分：一般，存在明显不足
     4分：良好，仅有少量瑕疵
     5分：优秀，无需改进
  </评分标准>

  <输出格式>
     {
      "origin_id": "{origin_id}",
      "评估结果": [
        {
          "轮次": "{1-N}",
          "统筹能力": "{1-5}",
          "适应能力": "{1-5}",
          "评分理由": "{评分理由}"
        }
      ]
     }
  </输出格式>
</评测提示>