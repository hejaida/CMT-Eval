{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import random\n",
    "import pandas as pd \n",
    "import aiohttp\n",
    "import asyncio\n",
    "import re\n",
    "import tracemalloc\n",
    "import nest_asyncio\n",
    "from openai import OpenAI\n",
    "tracemalloc.start()\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_acts = [\"追问\", \"建议\", \"补充\", \"修改\", \"反馈\"]\n",
    "\n",
    "ROLE_FEATURES = {\n",
    "    \"陈旭\": \"男, 程序员, 爱质疑, 常用互联网黑话、术语，言简意赅\",\n",
    "    \"朵朵\": \"女, 中学生, 好奇心强, 常用叠词、网络语\",\n",
    "    \"张梅\": \"女, 教师, 善引导, 常用语气词\",\n",
    "    \"齐业\": \"男, 企业职工, 爱反驳，表达直接, 常用方言俚语，常有语病\",\n",
    "    \"Tina\": \"女, 编辑, 注重细节, 有时中英混用，用词丰富\",\n",
    "    \"小刘\": \"男, 大学生, 表达夸张随性, 常用网络语、热梗\",\n",
    "    \"雅婷\": \"女, 职场新人, 对模型回复要求高, 常反复确认信息\",\n",
    "    \"王刚\": \"男, 银行职员, 考虑周全, 避免绝对化表达\"\n",
    "}\n",
    "\n",
    "def load_data_from_json(filename, start_index, num_records):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "        subset = data[start_index:start_index + num_records] if num_records else data[start_index:]\n",
    "        \n",
    "        queries = []\n",
    "        for item in subset:\n",
    "            queries.append({\n",
    "                \"ID\": item['ID'],\n",
    "                \"role\": item['role'],\n",
    "                \"initial_question\": item['initial_question'],\n",
    "                \"summary\": item['summary'],\n",
    "                \"qa_pairs\": item['qa_pairs'],\n",
    "                \"text\": item.get(\"text\", \"\") \n",
    "        return queries\n",
    "\n",
    "\n",
    "def generate_conversation_structure(source_data):\n",
    "    initial_query = source_data['initial_question'] \n",
    "    role = source_data['role']\n",
    "    evaluation_ability = \"上文记忆保持\"\n",
    "    num_rounds = random.randint(6, 8)\n",
    "\n",
    "    conversation_content = [{\"轮次\": 1, \"用户query\": initial_query, \"言语行为\": \"初始问题\"}]\n",
    "    used_speech_acts = []\n",
    "\n",
    "    for round_num in range(2, num_rounds + 1):\n",
    "        act = None\n",
    "\n",
    "        if round_num in [2, num_rounds, num_rounds // 2, num_rounds - 2]:\n",
    "            act = \"追问\"\n",
    "        if not act:\n",
    "            available_acts = [a for a in speech_acts if a not in used_speech_acts]\n",
    "            act = random.choice(available_acts) if available_acts else random.choice(speech_acts)\n",
    "\n",
    "        used_speech_acts.append(act)\n",
    "\n",
    "        conversation_content.append({\n",
    "            \"轮次\": round_num,\n",
    "            \"用户query\": \"\", \n",
    "            \"言语行为\": act\n",
    "        })\n",
    "\n",
    "    conversation_json = {\n",
    "        \"ID\": source_data['ID'],\n",
    "        \"评测能力\": evaluation_ability,\n",
    "        \"用户角色\": role, \n",
    "        \"summary\": source_data['summary'],\n",
    "        \"qa_pairs\": source_data['qa_pairs'],\n",
    "        \"text\": source_data['text'],  \n",
    "        \"会话内容\": conversation_content\n",
    "    }\n",
    "    return conversation_json\n",
    "\n",
    "def load_prompt_from_txt(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as txtfile:\n",
    "        prompt = txtfile.read().strip()\n",
    "        print('读取 prompt 成功')\n",
    "        return prompt\n",
    "\n",
    "async def generate_full_conversation(session, conversation_data, prompt_template, temperature, top_p, api_key, api_url):\n",
    "    user_role = conversation_data.get(\"用户角色\", \"\")\n",
    "    role_features = ROLE_FEATURES.get(user_role, \"\")\n",
    "    prompt_with_role = f\"{prompt_template}\\n### 角色特征: {role_features}\"\n",
    "\n",
    "    conversation_data_for_prompt = conversation_data.copy()\n",
    "    conversation_data_for_prompt.pop('text', None)\n",
    "\n",
    "    prompt_content = prompt_with_role + \"\\n\" + json.dumps(conversation_data_for_prompt, ensure_ascii=False)\n",
    "\n",
    "    client = OpenAI(base_url=api_url, api_key=api_key)\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model='anthropic/claude-3.5-sonnet',\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt_content\n",
    "                }\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "            top_p=top_p\n",
    "        )\n",
    "\n",
    "        response_message = completion.choices[0].message.content\n",
    "        print(\"生成的会话内容:\", response_message)\n",
    "\n",
    "        generated_conversation = json.loads(response_message)\n",
    "        return generated_conversation\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during API call: {e}\")\n",
    "        return None\n",
    "    \n",
    "async def generate_conversations(conversation_samples, prompt_template, temperature, top_p, api_key, api_url):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for conversation in conversation_samples:\n",
    "            conversation_data = generate_conversation_structure(conversation)\n",
    "\n",
    "            task = generate_full_conversation(session, conversation_data, prompt_template, temperature, top_p, api_key, api_url)\n",
    "            tasks.append(task)\n",
    "        generated_conversations = await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "        final_conversations = []\n",
    "        for gen_conv, original in zip(generated_conversations, conversation_samples):\n",
    "            if gen_conv is not None:\n",
    "                initial_query = f\"{original.get('text', '')}\\n{gen_conv['会话内容'][0].get('用户query', '')}\"\n",
    "                gen_conv[\"会话内容\"][0][\"用户query\"] = initial_query\n",
    "                final_conversations.append(gen_conv)\n",
    "        return final_conversations\n",
    "\n",
    "def save_transformed_data(transformed_data, output_file_path):\n",
    "    try:\n",
    "        with open(output_file_path, 'r+', encoding='utf-8') as output_file:\n",
    "            try:\n",
    "                existing_data = json.load(output_file)\n",
    "            except json.JSONDecodeError:\n",
    "                existing_data = []\n",
    "\n",
    "            if isinstance(existing_data, list):\n",
    "                if isinstance(transformed_data, list):\n",
    "                    existing_data.extend(transformed_data)\n",
    "                else:\n",
    "                    existing_data.append(transformed_data)\n",
    "            elif isinstance(existing_data, dict):\n",
    "                if isinstance(transformed_data, dict):\n",
    "                    existing_data.update(transformed_data)\n",
    "                else:\n",
    "                    print(\"现有数据是字典，新数据不是字典，无法合并！\")\n",
    "                    return\n",
    "            output_file.seek(0)\n",
    "            json.dump(existing_data, output_file, ensure_ascii=False, indent=2)\n",
    "    except FileNotFoundError:\n",
    "\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            json.dump(transformed_data, output_file, ensure_ascii=False, indent=2)\n",
    "\n",
    "def main():\n",
    "    input_json_filename = ''  # summary & QA \n",
    "    output_json_filename = ''  \n",
    "    prompt_filename = ''\n",
    "\n",
    "    temperature = 0.2\n",
    "    top_p = 0.7\n",
    "\n",
    "    api_key = ''\n",
    "    api_url = ''\n",
    "\n",
    "    start_index =\n",
    "    num_records = \n",
    "\n",
    "    try:\n",
    "        \n",
    "        conversation_samples = load_data_from_json(input_json_filename, start_index=start_index, num_records=num_records)\n",
    "        prompt_template = load_prompt_from_txt(prompt_filename)\n",
    "\n",
    "        if not conversation_samples:\n",
    "            print(\"未找到符合条件的会话样本。\")\n",
    "            return\n",
    "\n",
    "        generated_conversations = asyncio.run(\n",
    "            generate_conversations(conversation_samples, prompt_template, temperature, top_p, api_key, api_url)\n",
    "        )\n",
    "        if generated_conversations:\n",
    "            save_transformed_data(generated_conversations, output_json_filename)\n",
    "            print(f\"成功生成 {len(generated_conversations)} 个会话并写入 {output_json_filename}。\")\n",
    "        else:\n",
    "            print(\"未生成任何有效的会话内容。\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"运行过程中发生错误: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
